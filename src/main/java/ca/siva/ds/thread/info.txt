
key points:
>> Processes won't share resources among themselves, whereas threads can share resources from a process.
>> Global variables are accessed by all the threads. But there's a locking mechanism available inorder to apply the change.
>> Two types of concurrency models:
        1) Pre-emptive multitasking model => every thread gets cpu slice, as program doesn't have control over making the context switch
        2) Co-operative multitasking model => It's the opposite of 1, as program provides an instruction to the scheduler to make the context switch.
                cons: A malfunctioned program can run forever in this model.

>> Mutex and Semaphore are OS, lower level constructs.

>> Mutex: It allows only serialized access on a shared resource. for e.g., when there are multiple threads tries to acquire a lock,
        only one of the thread will eventually get access and the remaining threads will fall into a wait state.
        Another point is, the thread that acquired the lock can only be able to unlock the resource - it defines an ownership strategy.

>> Semaphore: Semaphore has a permit limit, that means that many number of threads can enter the crtical section, and once the max permit limit is reached.
            the remaining threads will go into a wait state. Semaphore solves the issue of missing signals.
             For e.g., a database can accept 100 connections, means 100 threads can acquire different connections of db.
             However, if a new one comes after connections are full, it will go to wait state until the existing connection is freed.

>> Mutex vs Semaphore:
        A semaphore can act as mutex, but mutex cannot masquerade as semaphore. Because semaphore has a signalling mechanism, which can be used to signal among threads.
        Also Semaphore doesn't have an owner ship strategy, that only the acquired thread can release the lock.

>> Monitor:
   Monitor is an entity provides lock, wait queue and re-entrance queue.
    Monitor provides mutual exclusion and a conditional variable. Usually when another thread, say T1 is waiting on a predicate(value), depending on the change by T2,

    --producer consumer problem--

     old consumer without monitor and only mutex:
        // This approach is very slower, as it consumes more cpu cycles
        void consumerCode() {
            mutex.acquire() // Acquire mutex
            while (predicate is false) {
                // release lock, so other thread can acquire the resource and change the value to true
                // acquire lock, check again whether the resource got updated or not.
            }
        }

     When monitor is used,
                void consumerCode() {
                    mutex.acquire() // Acquire mutex
                    while (predicate is false) {  // while loop is needed because, when the lock releases, and if there's another thread that can acquire lock and change the value.
                        condVar.wait() // Atomically, release lock and places the thread in wait queue, so other thread can acquire the resource and change the value to true,
                                       // then give a signal on the condVar, so the wait( here consumer) threads can be moved to entry set and start acquiring the monitor again for execution.
                    }
                }
                void producerCode() {
                   mutex.acquire() // Acquire mutex
                   predicate = true
                   condVar.signal() // Give a signal on the condVar, so the wait threads can be moved to entry queue and start acquiring the monitor again for execution.
                   mutex.release()
                }

>> Mutex vs Monitor:
    1) Mutex are provided by the os library/kernel and libraries provide an interface to invoke it. This makes them heavy and slower.
    2) Monitor is fast and light-weight, since it is provided by library itself, don't need to request OS. It used for maintaining synchronization among threads of a same process.
    3) A monitor is a mutex lock, which is implicitly associated with an object. Usually, when synchronized is used, mutex lock is created around the code.

>> In Java, every object is a conditional variable, it comes with wait() and notify() methods. Also, these methods need to be called inside a synchronized method (static methods too).
>> Hoare vs Mesa Monitors(follows the same concepts as discussed above).
>> In Hoare, the signaling thread make sure that waiting thread acquires the lock, so that no thread in the mean can alter the predicate value.
>> Java follows Mesa semantics. Mesa monitors are more efficient than Hoare Monitors.
>> Semaphore vs Monitor.
    >> Monitor is made up of a mutex and a condition variable.
    >> Semaphore can allow multiple threads to access the critical section. Whereas, monitor allows only single thread.
    >> In Semaphore, locking mechanism control is done by developer, which can be error prone. However, in Monitor, its done implicitly.
    >> Java monitors enforce correct locking by throwing the IllegalMonitorState exception, when methods are invoked without acquiring the associated lock.
    >> Semaphore is a lightweight, but error-proned.
>> Amdahl's law explains the speedup a program can be achieved at best by using additional computing resources. s(n) = 1 / ((1-p) + p /number of processors or threads)
>> Moore's law states that number of transistors per square inch on a chip with double every 2 years.
>> Atomic assignments:
      > Means, data won't change in the variable during the assignment. for e.g., when 2nd thread tries to do an assignment to a variable, while 1st thread also doing the same
      there's no chance that both data interleave on the variable.
      > Atomic assignments doesn't guarantee that the variable is thread safe. To make thread safe, use synchronized / locks.
>> Thread safe:
        > By default, all classes and API methods are thread safe.
        > Consider synchronized declared block of code as a critical section piece of code (mutex portion). There's a lock/monitor associated with the object once the caller acquires the lock.
         no other thread can invoke synchronized declared methods until the current thread releases the lock.
            for e.g., suppose there are 3 different synchronized methods on the same object, and 3 different threads tries to invoke those methods.
                and once any thread acquires the execution, remaining 2 other threads will be in wait state.
        > By using synchronized keyword, the main important ramification is, its implicitly acquires the monitor and releases the monitor lock by the same thread.
          However, in semaphores different methods can acquire the lock and release the lock.
          Refer to incorrectSynchronization example.
        > When synchronized is used, it may reduce the throughput. For e.g, having 2 fields and synchronized on their respective 2 getter methods, when the thread1 is accessing the first getter method,
          while the second thread accessing the second getter method, will go into wait state. This is more performance consuming.
          the solution is to lock at finer granularity, use 2 different locks for each property, so that both can be accessed in parallel.
>> wait() -> It is called inside a synchronized block by acquiring the monitor of the object. This makes atomically releases the lock and places the thread in a wait queue.
>> notify() -> It will notify one of the thread from the wait queue - it can be any random thread.
>> notifyAll() -> It notifies all the threads, so any random thread can acquire the lock.
        Sometimes it's better to use notifyAll, especially when there's a chance that single thread wont able to pick up the lock due to any expected reason, the other thread can acquire the lock.

>> synchronized(LOCK) {
       Thread.sleep(1000); // LOCK is held
   }
   synchronized(LOCK) {
       LOCK.wait(); // LOCK is not held
   }
>> When a sleeping / waiting  thread invoked, it will throw an interruptedException.
    when interrupt() is called on a thread, it just sets the value of flag to false, that is polled by wait() and sleep() methods,
    to check whether the flag is set to true or not.
>> ****Interrupting an normal thread(i.e, not in sleep mode), will simply set the flag to true.
>> Double and Long are not atomic assignments in java, as jvm uses 2 different 32 bits, which can interleave, so it should be denoted volatile when used with threads.
>> Volatile implies all writes occur directly into memory, instead of updating cpu cache. So, all the reading threads will have an updated value.
>> Volatile doesn't imply thread safety. e.g., when there are multiple threads writing to a same variable(volatile), then it doesn't guarantee thread safety.
 best case is use volatile, only when one thread is modifying the value and the remaining threads refer to the updated value of this variable.

>> Reentrant Lock:
     Upgrade of mutex is Reentrant lock. But here lock can be done in a different method and unlock in a different method.
     It throws IllegalMonitorStateException, when unlock is called without locking.
     Lock lock = new ReentrantLock();
     Condition condition = lock.newCondition();
     In Synchronized paradigm, there's only one wait-set associated with the object. But with the reentrant locks, there can be multiple condition variables on the same lock.

>>Thread states in Java:
         1) new
         2) runnable
         3) wait
         4) timed wait
         5) blocked
         6) terminated
>> Missed Signals: Signal was sent before awaiting on it; which can enable the await thread to block forever can case execution time out.
       Semaphores can be used to fix these type of missing signals.
>> It is always recommended to use semaphore.release() or lock.unlock() in a finally block, such that even if the failure happens in code, finally will execute and release the semaphore/rentrant lock.
>> Spurious wakeups:
    A thread can woken up without calling signal on it. A thread can wake up without being notified, interrupted or timing out.
    So, that's why application must guard on a condition variable as a check by using a while loop.
    e.g.,:
            synchronized(obj) {
                while (condition does not hold) {
                    obj.wait(timeout)
                }

            }

>> Locks can have a huge impact over performance, especially when the thread shared data/state is being contended for access by multiple threads.
    Locking cons:
        1) Thread scheduling vs useful work:
            when many threads are waiting to acquire a lock, and one wins the race condition to achieve the lock
             and do the work, will end up causing most of the time wasted in scheduling the remaining threads in compare to the work its getting done.
        2) Priority Inversion:
             A lower priority thread acquires the lock and never released due to page fault, scheduling issues etc can cause the priority thread in a blocked state.
        3) Liveness issues:
              a thread can run into an infinite loop, end up causing other threads in a blocked state; will end up a dead lock.
        4) locking, a heavy weight mechanism

>> Contention: Thread trying to acquire a lock.

>> In atomic, 2 main methods are available
        1) compareAndSwap
        2) compareAndSet

>> Atomic vs volatile:
        1) volatile variables can't be used for executing compound actions: read variable, write variable and update variable.
           volatile ensures, that certain expected state is true across different threads, while atomics ensure that operation on variables are performed atomically.
           volatile doesn't deal with atomicity.
    > Atomic operations are handled using compare and set(CAS) approach; it consumes only cpu cycles by avoiding scheduling overhead, which comes with threads.
    > Atomic operations are always faster than locking mechanism, as it occurs thru machine level atomic instructions, that allows no scheduling overhead.

>> An algorithm is called non-blocking if the failure or suspension oif a thread doesn't cause the failure or suspension of another thread.
>> An algorithm is called lock free, if at every step of the algorithm, some thread participant can make progress.

>> Lock Fairness: Usually when there are multiple threads trying to acquire a lock, only one of them can acquire the lock, especially the one that requests unfairly greater number of times.
java locks can be turned into fair locks by passing in the fair constructor parameter. However, they exhibit lower throughput.
>> ThreadPools: The main use of having thread pools, is thread stays in the pool, without deallocating it's resources, therefore the newer task can be submitted over a thread pool.
    In java, there's a ThreadpoolExecutor for creating thread pools.

>> Lack of cache coherency: Where thread's local cache is not in coherent(consistent) with the changes occur in the main memory.
    > JSR-133 was developed to tackle these issues. Within-thread as-if-serial semantics: all the statements inside the thread follow execution serially.
    > JMM(java memory model) do reordering of statements as long as the outcome of the program isn't altered.
    > Using writes without synchrnoization can cause datarace, and with re-ordering of JVM statements can end up returning different results.
    > Happens-before memory model: Unlocking monitor happens before the monitor locking.

Producer consumer problem:
    Problem statement:
        Producer must be blocked, when the size reaches the maximum capacity,
        same as well for the consumer when there's no element, it should be blocked. once a new element is added to the queue, it should notify the blocking consumer.




